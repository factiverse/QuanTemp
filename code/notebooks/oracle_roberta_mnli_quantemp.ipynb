{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "33cc7df771c845bd869d6b5124f2604d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f07654bb49c64b1aa30940181d5e4574",
              "IPY_MODEL_34f0c3999b5c4bf295102050cb6052d4",
              "IPY_MODEL_a76ca4bdf1784163878dae276beca5d5",
              "IPY_MODEL_cef13963e753410c8812b92daebdd48f"
            ],
            "layout": "IPY_MODEL_89226fc74b2c44a2978c4d0b43b60739"
          }
        },
        "794716544ed3491aba47432a4f3afca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf150bd16c424916a8ba79e763d07f1d",
            "placeholder": "​",
            "style": "IPY_MODEL_469f372a38644513abf1374edc48ee3d",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "f64930120a7748eaa8a743c77e52cc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ad973a985d3a421eaa5c1a7ca55420ed",
            "placeholder": "​",
            "style": "IPY_MODEL_71e781b197b5496e8809b7fff046a20e",
            "value": ""
          }
        },
        "931cbe93dc6546ba970a79e0cbf678bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_8bdd37fccf354d9793047799a966f2a0",
            "style": "IPY_MODEL_39317c1aa3694777947eab03b2dd3ff5",
            "value": true
          }
        },
        "18b0770757c241de8253b1d94ee568fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c71f8c507eab42e3baa08939664d3029",
            "style": "IPY_MODEL_804dbceb1d564e0e8a0fdc5e57f2c489",
            "tooltip": ""
          }
        },
        "0d7e62772c6f451d9575dd5df95d879c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbb79f0a4ca246a18381b836665264e4",
            "placeholder": "​",
            "style": "IPY_MODEL_089e03c3f97749b99e6493cd58176603",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "89226fc74b2c44a2978c4d0b43b60739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "cf150bd16c424916a8ba79e763d07f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "469f372a38644513abf1374edc48ee3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad973a985d3a421eaa5c1a7ca55420ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e781b197b5496e8809b7fff046a20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bdd37fccf354d9793047799a966f2a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39317c1aa3694777947eab03b2dd3ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c71f8c507eab42e3baa08939664d3029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804dbceb1d564e0e8a0fdc5e57f2c489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "cbb79f0a4ca246a18381b836665264e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "089e03c3f97749b99e6493cd58176603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6339b7381c54dda8b7876bca36c3054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31e6b85700304187bf5197da351a125e",
            "placeholder": "​",
            "style": "IPY_MODEL_248d065f02eb4f57a33b60df8dd9fb24",
            "value": "Connecting..."
          }
        },
        "31e6b85700304187bf5197da351a125e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "248d065f02eb4f57a33b60df8dd9fb24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f07654bb49c64b1aa30940181d5e4574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_169e51f8ece34774baceefbbdff5276d",
            "placeholder": "​",
            "style": "IPY_MODEL_fb7ce11bf3a14bc3bbca96cbbb4f45ef",
            "value": "Token is valid (permission: write)."
          }
        },
        "34f0c3999b5c4bf295102050cb6052d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521fe75d24e2402f9a4566d82b4602fd",
            "placeholder": "​",
            "style": "IPY_MODEL_6991b5be37164ec09eb84d9935c4a1f5",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "a76ca4bdf1784163878dae276beca5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0610958751c4fcba8cd0a042c79dcd0",
            "placeholder": "​",
            "style": "IPY_MODEL_261eecd1fd6e4b17a9e9bcb574bc9f5b",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "cef13963e753410c8812b92daebdd48f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0de8bc5290ba41a78ab6cac1a9e99c13",
            "placeholder": "​",
            "style": "IPY_MODEL_0c92603a817143ab8b4bf460a09f3245",
            "value": "Login successful"
          }
        },
        "169e51f8ece34774baceefbbdff5276d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb7ce11bf3a14bc3bbca96cbbb4f45ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "521fe75d24e2402f9a4566d82b4602fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6991b5be37164ec09eb84d9935c4a1f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0610958751c4fcba8cd0a042c79dcd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "261eecd1fd6e4b17a9e9bcb574bc9f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0de8bc5290ba41a78ab6cac1a9e99c13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c92603a817143ab8b4bf460a09f3245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egtdWTvcOeTy",
        "outputId": "280c1e96-d7c9-4c5f-ba0f-3b9035caacfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import torch\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AlOzas-OzjA",
        "outputId": "1c46f3ab-3acd-49eb-b5c1-3fe4202deed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,AutoModel\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-large-mnli', do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_-uxEt3O1Y_",
        "outputId": "46a862d9-f58d-4bba-9a96-7e7149cae048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"train_claims_quantemp.json\") as f:\n",
        "  train_data = json.load(f)\n",
        "len(train_data\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwlWUAIgAKGn",
        "outputId": "6f0150d8-fa97-4ed0-ec48-4103a917c39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9932"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjbPPEMKW4CM",
        "outputId": "7e60411d-5bf1-4e27-f0bc-19b8280c1a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sources': [{'link': 'http://tsn.ua/politika/pid-zavalami-zgoriloyi-bazi-berkutu-u-lvovi-znayshli-dvoh-mertvih-silovikiv-335713.html',\n",
              "   'description': 'occured'},\n",
              "  {'link': 'http://24tv.ua/home/showSingleNews.do?lvovskiy_berkut_stal_na_koleni_pered_lvovyanami_video&objectId=413464&lang=ru',\n",
              "   'description': 'kneeled'}],\n",
              " 'country_of_origin': 'ukraine',\n",
              " 'label': 'False',\n",
              " 'published': '2014-03-26',\n",
              " 'url': 'https://www.stopfake.org/en/fake-commandos-from-berkut-who-refused-to-kneel-have-been-burned-alive-in-lviv/',\n",
              " 'crawled_date': '2014-03-26T10:38:09',\n",
              " 'lang': 'en',\n",
              " 'fact_source': 'stopfake',\n",
              " 'supported': True,\n",
              " 'label_original': 'FAKE',\n",
              " 'claim': 'FAKE:  Commandos from &#8220;Berkut&#8221; who refused to kneel have been burned alive in Lviv',\n",
              " 'doc': 'The Russian TV channel “Russia 1” aired a program called “Evil spirits of Maydan: mystic of Ukrainian mayhem”. The program, among other things, referred to the claim that two soldiers of “Berkut”, who refused to kneel in front of Lviv Maydan and recognize the current government, allegedly were burned alive. https://www.youtube.com/watch?v=SUDH0Qbjuao This was reported by the head of the so-called Russian community of Dnepropetrovsk Victor Trukhov. He says, two “Berkut” solders were put on their knees publicly and then burned in Lviv. However, contrary to this claim, a fire occured in Lviv on February 20, 2014 where people from security forces were caught in a fire. The fire started after a powerful explosion in the security forces basis, after which one officer in uniform and one in civilian clothes were pulled from the rubble. Commandos from “Berkut” kneeled on 24 February. Lviv citizens who came to the Maydan, were shouting “Shame!” and throwing small objects at security forces. To prevent any possible violence against “Berkut” soldiers, Self-Defense soldiers surrounded “Berkut”, and the priest was calming down people. \\xa0 People made the security forces to kneel on stage, and then one of the special forces soldier promised that “Berkut” will always be on the side of the people and assured that Lviv “Berkut” was not involved in the fighting in Kyiv. After the “ceremony” the commandos were taken away in the tram. Accordingly, the fire was the result of an accident and not the result of public humiliation of “Berkut”.',\n",
              " 'complexity_class': 'complex',\n",
              " 'numerical': True,\n",
              " 'taxonomy_label': 'statistical'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"val_claims_quantemp.json\") as f:\n",
        "  val_data = json.load(f)\n",
        "len(val_data\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea6PlA4bW5UO",
        "outputId": "aa084206-c1b5-4799-8952-3e8cb84f34ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3084"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_data[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT-q3h48kxdg",
        "outputId": "d5290e0b-29f5-4839-c1b2-065411713679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'stated_in': 'stated on October 5, 2021 in a tweet',\n",
              " 'date_stated': '2021-10-05',\n",
              " 'sources': [{'link': 'https://twitter.com/RepFeenstra/status/1445480085243367427?s=20',\n",
              "   'description': 'Twitter, Rep. Randy Feenstra, Oct. 5, 2021'},\n",
              "  {'link': 'https://twitter.com/JenniferJJacobs/status/1445477075947646978?s=20',\n",
              "   'description': 'Twitter, Jennifer Jacobs, Oct. 5, 2021'},\n",
              "  {'link': 'https://t.co/Qk1Chwurc3?amp=1',\n",
              "   'description': 'U.S. Energy Information Administration, Annual Energy Outlook 2021, 2021'},\n",
              "  {'link': 'https://www.desmoinesregister.com/story/money/agriculture/2020/09/14/epa-says-reject-requests-cut-ethanol-use/5790852002/',\n",
              "   'description': 'The Des Moines Register, \"With rural voters’ support at risk, Trump administration backs most ethanol mandates,\" by Donnelle Eller, Sept. 14, 2020'},\n",
              "  {'link': 'https://joebiden.com/2020/09/15/statement-by-vice-president-joe-biden-on-need-to-stand-with-farmers-and-biofuel-producers-after-donald-trumps-latest-insult-to-ethanol-industry/',\n",
              "   'description': 'Biden-Harris campaign, \"Statement by VP Biden on standing with farmers & biofuels producers after Trump’s latest insult to ethanol industry,\" Sept. 15, 2020'},\n",
              "  {'link': 'https://www.reuters.com/article/us-usa-biofuels/u-s-epa-grants-three-biofuel-waivers-to-refiners-before-trump-leaves-office-idUSKBN29O2SE',\n",
              "   'description': 'Reuters, \"U.S. EPA grants three biofuel waivers to refiners before Trump leaves office,\" Jan. 19, 2021'},\n",
              "  {'link': 'https://millermeeks.house.gov/media/press-releases/miller-meeks-urges-president-biden-keep-promises-biofuels-producers',\n",
              "   'description': 'Rep. Mariannette Miller-Meeks news release, \"Miller-Meeks Urges President Biden to Keep Promises to Biofuels Producers, Sept. 22, 2021'},\n",
              "  {'link': 'http://biomassmagazine.com/articles/18025/iowa-lawmakers-urge-biden-to-prioritize-biofuels',\n",
              "   'description': 'Biomass Magazine, \"Iowa lawmakers urge Biden to prioritize biofuels,\" by Erin Voegele, May 25, 2021'},\n",
              "  {'link': 'https://www.iowaagribusinessradionetwork.com/iowa-lawmakers-holding-president-biden-to-his-biofuels-promise/',\n",
              "   'description': 'Iowa Agribusiness Radio Network, \"Iowa lawmakers holding President Biden to his biofuels promise,\" by Riley Smith, May 31, 2021'},\n",
              "  {'link': 'https://www.desmoinesregister.com/story/news/politics/2021/04/21/iowa-rep-cindy-axne-pushes-add-ethanol-biodiesel-measures-to-president-joe-biden-infrastructure-deal/7284346002/',\n",
              "   'description': 'Des Moines Register, \"U.S. Rep. Cindy Axne pushes to include ethanol measures in $2 trillion infrastructure deal,\" by Brianne Pfannenstiel, April 21, 2021'},\n",
              "  {'link': 'https://biofuels-news.com/news/ad-campaign-urges-biden-not-to-make-rfs-u-turn/',\n",
              "   'description': 'Biofuels International, \"Ad campaign urges Biden not to make RFS U-turn,\" Aug. 13, 2021'},\n",
              "  {'link': 'https://www.hydrocarbonprocessing.com/news/2021/09/eia-releases-plant-level-us-biofuels-production-capacity-data',\n",
              "   'description': 'HydrocarbonProcessing.com, \"EIA releases plant-level U.S. biofuels production capacity data,\" Sept. 13, 2021'},\n",
              "  {'link': 'https://www.eia.gov/petroleum/ethanolcapacity/',\n",
              "   'description': 'U.S. Energy Information Administration, \"U.S. Fuel Ethanol Plant Production Capacity,\" Sept. 3, 2021'}],\n",
              " 'country_of_origin': 'usa',\n",
              " 'label': 'True',\n",
              " 'published': '2021-10-28',\n",
              " 'url': 'https://www.politifact.com/factchecks/2021/oct/28/randy-feenstra/biden-administration-predicted-liquid-fuel-cars-ou/',\n",
              " 'crawled_date': '2022-10-06T21:00:06',\n",
              " 'speaker': 'Randy Feenstra',\n",
              " 'factchecker': 'Sabine Martin',\n",
              " 'topic': ['Climate Change',\n",
              "  'Energy',\n",
              "  'Transportation',\n",
              "  'Iowa',\n",
              "  'Randy Feenstra'],\n",
              " 'lang': 'en',\n",
              " 'fact_source': 'politifact',\n",
              " 'supported': True,\n",
              " 'gpt3_claim': 'The Biden administration published a study concluding 4 of 5 new cars on the road by 2050 will still require liquid fuels.',\n",
              " 'gpt3_label': 'Partially True',\n",
              " 'gpt3_queries': ['Biden administration study on liquid fuels in new cars by 2050',\n",
              "  \"U.S. Energy Information Administration's 2021 Annual Energy Outlook report\",\n",
              "  'Future of automobile industry and liquid fuels'],\n",
              " 'gpt3_summary': \"The U.S. Energy Information Administration's 2021 Annual Energy Outlook report projects that 79% of new vehicles sold will still use liquid fuels in 2050, accounting for 95% of sales in 2020. A report from the Biden administration was cited to support the claim that 4 out of 5 new cars will require liquid fuels by 2050. Biden did not provide a timeline for when electric power would come close to the share of the automobile market so it is not clear whether the claim is true, false or partially true/false.\",\n",
              " 'label_original': 'true',\n",
              " 'summary': 'U.S. Rep. Randy Feenstra, R-Iowa, tweeted that four out of five new cars in 2050 will still require liquid fuels, and that the projection contradicts an Oct. 5 statement from President Joe Biden touting electric as an energy source for automobiles.  The U.S. Energy Information Administration’s 2021 Annual Energy Outlook report states that a majority, 79%, of vehicles will have liquid fuel by 2050. Ethanol consumption is important in Iowa because the state leads the nation in ethanol production.',\n",
              " 'claim': 'The Biden administration \"published a study concluding 4 (of) 5 new cars on the road by 2050 will still require liquid fuels.\"',\n",
              " 'doc': 'President Joe Biden was in Michigan’s auto industry hub on Oct. 5 when he said, \"the whole world knows that the future of the auto industry is electric.\" Rep. Randy Feenstra, R-Iowa, had a quick response, writing on Twitter: \".@POTUS no it’s not — in fact, your own administration published a study concluding 4/5 new cars on the road by 2050 will still require liquid fuels ... \"It’s past time Biden lives up to his promise to expand clean-burning #biofuels. Don’t mess with the RFS!\" Feenstra is correct about the share of cars in the United States projected to use liquid fuels. The U.S. Energy Information Administration’s 2021 Annual Energy Outlook report, which projects the nation’s environmental plans through 2050, says about 79% of new vehicle sales will be powered by liquid fuels — gasoline and blends that include up to 85% ethanol — in 2050. They accounted for 95% of sales in 2020, the report states. PolitiFact contacted Feenstra’s communications staff over 10 times for comment but did not receive a response. However, Feenstra’s tweet shared the link to his sourcing, and on page 15, the federal report notes that, while electric energy’s biggest demand growth area is transportation, the share will be small — less than 3%: \"Current laws and regulations are not projected to induce much market growth, despite continuing improvements in electric vehicles (EVs) through evolutionary market developments. Both vehicle sales and utilization (miles driven) would need to increase substantially for EVs to raise electric power demand growth rates by more than a fraction of a percentage point per year.\" And, on the report’s page 26: \"Because most light-duty vehicles have internal combustion engines, motor gasoline remains the major transportation fuel through 2050 as personal travel returns to pre-pandemic per-driver levels in the longer term.\" While 2050 is 29 years down the road, Biden did not state in Michigan a time limit on when he thinks electric power would come close to liquid fuels’ share of the automobile market. Nor did he state in detail what that future for electric power for automobiles would be. His administration’s Annual Energy Outlook reports that it is not predicting future energy use; rather it is a projection based on assumptions and methodologies that can be changed when subjected to changes in technology, demographics and resources. The report also notes that it is a response to the Department of Energy Organization Act of 1977. That law requires the U.S. Energy Information Administration to produce annual reports on trends and projections for energy use and supply, the report notes. But Feenstra was precise with his facts, and is not alone reminding Biden to support biofuels. Other Iowa congressional members, Republican and Democrat, have pushed for biofuels support, regardless of who is president. So has the biofuels industry. The reason? Iowa leads the nation when it comes to producing biofuels from farm crops. It has capacity to produce 4.6 billion gallons, double the 2.3 billion in the No. 2 state, Nebraska. While we focused this story on predicted biofuels use in vehicles, it’s worth noting that Biden promised support for biofuels in a Sept. 9, 2020, campaign statement that criticized a pre-election policy reversal by then-President Donald Trump on biofuels. Trump’s reversal led to his administration’s rejection of oil refinery industry requests to be exempt from requirements to blend certain amounts of ethanol and biodiesel in gasoline: \"A Biden-Harris Administration will fight for family farmers and revitalize rural economies — from keeping our promises to farmers by ushering in a new era of biofuels, to investing in the broadband infrastructure and rural health care access that families and communities need,\" the Biden statement read. Trump reversed course again and approved on Jan. 19, 2021, just before leaving office, three biofuel waivers for refineries. Feenstra said the Biden Administration predicts that four out of five new cars on the road will require liquid fuels in 2050 and he cites the source. That source, a report from the Biden Administration, states that 79% of vehicles on the road will require liquid fuels by 2050. We rate Feenstra’s statement to be True.',\n",
              " 'complexity_class': 'complex',\n",
              " 'numerical': True,\n",
              " 'taxonomy_label': 'statistical'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "LE = LabelEncoder()"
      ],
      "metadata": {
        "id": "7cYv6F4Nk4SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(data):\n",
        "  features = []\n",
        "  evidences = []\n",
        "\n",
        "  for index, fact in enumerate(data):\n",
        "    claim = fact[\"claim\"]\n",
        "\n",
        "\n",
        "    feature = \"[Claim]:\"+claim+\"[Evidences]:\"+fact[\"doc\"]\n",
        "    features.append(feature)\n",
        "  return features\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8eKFjiC3i8Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = get_features(train_data)"
      ],
      "metadata": {
        "id": "qY7Gux6Yn5rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ5AoF54oV2t",
        "outputId": "77cf02d1-d04d-4200-b269-a1d6769c2038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9935"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "FHml9DUHn_bh",
        "outputId": "d9aa891b-3b44-40b4-d955-b36237584a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[Claim]:In her budget speech, Nirmala Sitharaman claimed that the Government distributed 35,000 crore LED bulbs in the country.[Evidences]:Did Finance Minister Nirmala Sitharaman claim the government distributed 35,000 crore LED bulbs under the Ujala scheme? This would imply the Modi govt gave about 300 bulbs to every person in India. At least this is what is being claimed by some social media users who are sharing a screenshot from a news segment on business channel CNBC Awaaz. The photo shows Sitharaman delivering her budget speech while a caption at the bottom reads - \"35,000 crore LED bulb baantein gaye\" (35,000 crore LED bulbs were distributed). The snapshot gives the impression that Sitharaman said this sentence in her speech. Netizens are displaying shock at this whopping number believing that the finance minister\\'s statement is true. Some Congress leaders are also trolling her by sharing the screenshot of the news channel. But, India Today Anti Fake News War Room (AFWA) found that Sitharaman never said that 35,000 crore LED bulbs were distributed in the country in her speech. In fact, she said that approximately 35 crore LED bulbs were distributed under the Ujala scheme. Among many who have shared the news channel\\'s screenshot is Congress spokesperson Shobha Oza who tweeted the picture. Her tweet was retweeted more than 350 times and had over 1,500 likes by the time of writing this story. Former Cabinet Minister in Haryana government, Mahender Pratap Singh also trolled Sitharaman, believing the news to be true. There are some more verified social media users who have shared the same image of the news channel. 125 35000 LED - 280 .. , ...? pic.twitter.com/p8JKRWrMPb Sachin Chaudhary (@SChaudharyINC) July 6, 2019 Every Indian after receiving 300 LED bulbs each, as claimed by Dumb Sitharaman !! (She claims 35000 crore LED bulbs have been distributed, which means every Indian must have got approx 300 each) pic.twitter.com/7Nsz0ZYLm6 Gaurav Pandhi (@GauravPandhi) July 6, 2019 At 1:06:47, in the YouTube video of the Budget 2019 speech, one can hear Finance Minister Nirmala Sitharaman saying \"approximately 35 crore LEDs have been distributed under Ujala Yojana\". The text speech of the budget also reads \"approximately 35 crore LED bulbs\", and not \"35,000 crore LEDs\". Website of UJALA also states that till July 6, more than 35 crore LEDs have been distributed in the country. A senior editor at CNBC Awaaz spoke to us and confirmed that the wrong figure was aired due to a typo which was corrected when noticed. INDIA TODAY FACT CHECK Claim In her budget speech, Nirmala Sitharaman claimed that the Government distributed 35,000 crore LED bulbs in the country. Conclusion Sitharaman never said this in the budget speech. She stated that about 35 crore LED bulbs were distributed under UJALA scheme. JHOOTH BOLE KAUVA KAATE The number of crows determines the intensity of the lie. 1 Crow: Half True 2 Crows: Mostly lies 3 Crows: Absolutely false'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_features = get_features(val_data)"
      ],
      "metadata": {
        "id": "SeHEwL3doMD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ-ipHaHoiY-",
        "outputId": "b8326a13-bc9f-4d94-b0d4-6c572b6551d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3084"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_features[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Iyh75sm2ok_6",
        "outputId": "ebdcbc0d-2a1d-415d-8eaf-219feadadc1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[Claim]:Video of show Pakistani players celebrating the rain-hit match against India in Asia Cup 2023[Evidences]:The first Asia Cup encounter between India and Pakistan was washed away by rain on September 2, 2023. Against this backdrop, a viral video showing Pakistani players celebrating in the dressing room is doing the rounds on social media. Many users claim that players were celebrating cancellation of the match due to rain.A Facebook user posted the viral post with a caption:मैं तो कुछ और ही सोचा था कल एक पोस्ट भी की लेकिन ये तो सुपर फट्टू निकलेबारिश के कारण मैच रद्द होने के बाद पाकिस्तान के ड्रेसिंग रूम से लीक हुआ फुटेज:#INDvPAK | #AsiaCup2023(English translation: I was thinking something else yesterday I posted a clip but it turned out to be super stupid Footage leaked from Pakistan's dressing room after match was cancelled due to rain: #INDvPAK | #AsiaCup2023)You can check the post here.FACT CHECKNewsMobile fact-checked the viral post, and found it to be misleading.Running a Reverse Image Search of the video keyframes, the NM team identified a tweet on the official handle of Pakistan Cricket, dated September 2022. The video looks like a longer version of the viral post. As per its caption, the clip is from Pakistan's win over India in the 2022 Asia Cup.The same video was also published on the official YouTube channel of Pakistan Cricket on September 4, 2022. This clarifies that it has nothing to do with the ongoing Asia Cup 2023.Firstpost, too, reported on the raw celebrations by Pakistani players after beating India in the last-over thriller in Asia Cup 2022.Therefore, we can conclusively say that the viral video, claiming to show Pakistani players celebrating the rain-hit match against India in Asia Cup 2023, is misleading.If you want to fact-check any story, WhatsApp it now on +91 11 7127 9799FAKE NEWS BUSTER Name Email Phone Picture/video Picture/video url Description ΔClick here for Latest News updates and viral videos on our AI-powered smart news\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = [fact[\"label\"] for fact in train_data]\n",
        "val_labels = [fact[\"label\"] for fact in val_data]"
      ],
      "metadata": {
        "id": "98BSyfIZontr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_final = LE.fit_transform(train_labels)\n",
        "train_labels_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJYf-sJ4pHCd",
        "outputId": "77bb17b3-284b-4854-ce83-b2f344f11c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_final[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cjPop6cpdiA",
        "outputId": "58e7b625-980f-424c-91f0-a7d1436f2566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels_final = LE.transform(val_labels)\n",
        "val_labels_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dO586pApTPH",
        "outputId": "c5837a6e-bc2b-43aa-a6f2-a9ee8cf9ddd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDzDVC1lnmwD",
        "outputId": "317fbe01-8dea-4900-e684-f6d3265c170e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'stated_in': 'stated on October 5, 2021 in a tweet',\n",
              " 'date_stated': '2021-10-05',\n",
              " 'sources': [{'link': 'https://twitter.com/RepFeenstra/status/1445480085243367427?s=20',\n",
              "   'description': 'Twitter, Rep. Randy Feenstra, Oct. 5, 2021'},\n",
              "  {'link': 'https://twitter.com/JenniferJJacobs/status/1445477075947646978?s=20',\n",
              "   'description': 'Twitter, Jennifer Jacobs, Oct. 5, 2021'},\n",
              "  {'link': 'https://t.co/Qk1Chwurc3?amp=1',\n",
              "   'description': 'U.S. Energy Information Administration, Annual Energy Outlook 2021, 2021'},\n",
              "  {'link': 'https://www.desmoinesregister.com/story/money/agriculture/2020/09/14/epa-says-reject-requests-cut-ethanol-use/5790852002/',\n",
              "   'description': 'The Des Moines Register, \"With rural voters’ support at risk, Trump administration backs most ethanol mandates,\" by Donnelle Eller, Sept. 14, 2020'},\n",
              "  {'link': 'https://joebiden.com/2020/09/15/statement-by-vice-president-joe-biden-on-need-to-stand-with-farmers-and-biofuel-producers-after-donald-trumps-latest-insult-to-ethanol-industry/',\n",
              "   'description': 'Biden-Harris campaign, \"Statement by VP Biden on standing with farmers & biofuels producers after Trump’s latest insult to ethanol industry,\" Sept. 15, 2020'},\n",
              "  {'link': 'https://www.reuters.com/article/us-usa-biofuels/u-s-epa-grants-three-biofuel-waivers-to-refiners-before-trump-leaves-office-idUSKBN29O2SE',\n",
              "   'description': 'Reuters, \"U.S. EPA grants three biofuel waivers to refiners before Trump leaves office,\" Jan. 19, 2021'},\n",
              "  {'link': 'https://millermeeks.house.gov/media/press-releases/miller-meeks-urges-president-biden-keep-promises-biofuels-producers',\n",
              "   'description': 'Rep. Mariannette Miller-Meeks news release, \"Miller-Meeks Urges President Biden to Keep Promises to Biofuels Producers, Sept. 22, 2021'},\n",
              "  {'link': 'http://biomassmagazine.com/articles/18025/iowa-lawmakers-urge-biden-to-prioritize-biofuels',\n",
              "   'description': 'Biomass Magazine, \"Iowa lawmakers urge Biden to prioritize biofuels,\" by Erin Voegele, May 25, 2021'},\n",
              "  {'link': 'https://www.iowaagribusinessradionetwork.com/iowa-lawmakers-holding-president-biden-to-his-biofuels-promise/',\n",
              "   'description': 'Iowa Agribusiness Radio Network, \"Iowa lawmakers holding President Biden to his biofuels promise,\" by Riley Smith, May 31, 2021'},\n",
              "  {'link': 'https://www.desmoinesregister.com/story/news/politics/2021/04/21/iowa-rep-cindy-axne-pushes-add-ethanol-biodiesel-measures-to-president-joe-biden-infrastructure-deal/7284346002/',\n",
              "   'description': 'Des Moines Register, \"U.S. Rep. Cindy Axne pushes to include ethanol measures in $2 trillion infrastructure deal,\" by Brianne Pfannenstiel, April 21, 2021'},\n",
              "  {'link': 'https://biofuels-news.com/news/ad-campaign-urges-biden-not-to-make-rfs-u-turn/',\n",
              "   'description': 'Biofuels International, \"Ad campaign urges Biden not to make RFS U-turn,\" Aug. 13, 2021'},\n",
              "  {'link': 'https://www.hydrocarbonprocessing.com/news/2021/09/eia-releases-plant-level-us-biofuels-production-capacity-data',\n",
              "   'description': 'HydrocarbonProcessing.com, \"EIA releases plant-level U.S. biofuels production capacity data,\" Sept. 13, 2021'},\n",
              "  {'link': 'https://www.eia.gov/petroleum/ethanolcapacity/',\n",
              "   'description': 'U.S. Energy Information Administration, \"U.S. Fuel Ethanol Plant Production Capacity,\" Sept. 3, 2021'}],\n",
              " 'country_of_origin': 'usa',\n",
              " 'label': 'True',\n",
              " 'published': '2021-10-28',\n",
              " 'url': 'https://www.politifact.com/factchecks/2021/oct/28/randy-feenstra/biden-administration-predicted-liquid-fuel-cars-ou/',\n",
              " 'crawled_date': '2022-10-06T21:00:06',\n",
              " 'speaker': 'Randy Feenstra',\n",
              " 'factchecker': 'Sabine Martin',\n",
              " 'topic': ['Climate Change',\n",
              "  'Energy',\n",
              "  'Transportation',\n",
              "  'Iowa',\n",
              "  'Randy Feenstra'],\n",
              " 'lang': 'en',\n",
              " 'fact_source': 'politifact',\n",
              " 'supported': True,\n",
              " 'gpt3_claim': 'The Biden administration published a study concluding 4 of 5 new cars on the road by 2050 will still require liquid fuels.',\n",
              " 'gpt3_label': 'Partially True',\n",
              " 'gpt3_queries': ['Biden administration study on liquid fuels in new cars by 2050',\n",
              "  \"U.S. Energy Information Administration's 2021 Annual Energy Outlook report\",\n",
              "  'Future of automobile industry and liquid fuels'],\n",
              " 'gpt3_summary': \"The U.S. Energy Information Administration's 2021 Annual Energy Outlook report projects that 79% of new vehicles sold will still use liquid fuels in 2050, accounting for 95% of sales in 2020. A report from the Biden administration was cited to support the claim that 4 out of 5 new cars will require liquid fuels by 2050. Biden did not provide a timeline for when electric power would come close to the share of the automobile market so it is not clear whether the claim is true, false or partially true/false.\",\n",
              " 'label_original': 'true',\n",
              " 'summary': 'U.S. Rep. Randy Feenstra, R-Iowa, tweeted that four out of five new cars in 2050 will still require liquid fuels, and that the projection contradicts an Oct. 5 statement from President Joe Biden touting electric as an energy source for automobiles.  The U.S. Energy Information Administration’s 2021 Annual Energy Outlook report states that a majority, 79%, of vehicles will have liquid fuel by 2050. Ethanol consumption is important in Iowa because the state leads the nation in ethanol production.',\n",
              " 'claim': 'The Biden administration \"published a study concluding 4 (of) 5 new cars on the road by 2050 will still require liquid fuels.\"',\n",
              " 'doc': 'President Joe Biden was in Michigan’s auto industry hub on Oct. 5 when he said, \"the whole world knows that the future of the auto industry is electric.\" Rep. Randy Feenstra, R-Iowa, had a quick response, writing on Twitter: \".@POTUS no it’s not — in fact, your own administration published a study concluding 4/5 new cars on the road by 2050 will still require liquid fuels ... \"It’s past time Biden lives up to his promise to expand clean-burning #biofuels. Don’t mess with the RFS!\" Feenstra is correct about the share of cars in the United States projected to use liquid fuels. The U.S. Energy Information Administration’s 2021 Annual Energy Outlook report, which projects the nation’s environmental plans through 2050, says about 79% of new vehicle sales will be powered by liquid fuels — gasoline and blends that include up to 85% ethanol — in 2050. They accounted for 95% of sales in 2020, the report states. PolitiFact contacted Feenstra’s communications staff over 10 times for comment but did not receive a response. However, Feenstra’s tweet shared the link to his sourcing, and on page 15, the federal report notes that, while electric energy’s biggest demand growth area is transportation, the share will be small — less than 3%: \"Current laws and regulations are not projected to induce much market growth, despite continuing improvements in electric vehicles (EVs) through evolutionary market developments. Both vehicle sales and utilization (miles driven) would need to increase substantially for EVs to raise electric power demand growth rates by more than a fraction of a percentage point per year.\" And, on the report’s page 26: \"Because most light-duty vehicles have internal combustion engines, motor gasoline remains the major transportation fuel through 2050 as personal travel returns to pre-pandemic per-driver levels in the longer term.\" While 2050 is 29 years down the road, Biden did not state in Michigan a time limit on when he thinks electric power would come close to liquid fuels’ share of the automobile market. Nor did he state in detail what that future for electric power for automobiles would be. His administration’s Annual Energy Outlook reports that it is not predicting future energy use; rather it is a projection based on assumptions and methodologies that can be changed when subjected to changes in technology, demographics and resources. The report also notes that it is a response to the Department of Energy Organization Act of 1977. That law requires the U.S. Energy Information Administration to produce annual reports on trends and projections for energy use and supply, the report notes. But Feenstra was precise with his facts, and is not alone reminding Biden to support biofuels. Other Iowa congressional members, Republican and Democrat, have pushed for biofuels support, regardless of who is president. So has the biofuels industry. The reason? Iowa leads the nation when it comes to producing biofuels from farm crops. It has capacity to produce 4.6 billion gallons, double the 2.3 billion in the No. 2 state, Nebraska. While we focused this story on predicted biofuels use in vehicles, it’s worth noting that Biden promised support for biofuels in a Sept. 9, 2020, campaign statement that criticized a pre-election policy reversal by then-President Donald Trump on biofuels. Trump’s reversal led to his administration’s rejection of oil refinery industry requests to be exempt from requirements to blend certain amounts of ethanol and biodiesel in gasoline: \"A Biden-Harris Administration will fight for family farmers and revitalize rural economies — from keeping our promises to farmers by ushering in a new era of biofuels, to investing in the broadband infrastructure and rural health care access that families and communities need,\" the Biden statement read. Trump reversed course again and approved on Jan. 19, 2021, just before leaving office, three biofuel waivers for refineries. Feenstra said the Biden Administration predicts that four out of five new cars on the road will require liquid fuels in 2050 and he cites the source. That source, a report from the Biden Administration, states that 79% of vehicles on the road will require liquid fuels by 2050. We rate Feenstra’s statement to be True.',\n",
              " 'complexity_class': 'complex',\n",
              " 'numerical': True,\n",
              " 'taxonomy_label': 'statistical'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_labels_final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FardkyUtyT2B",
        "outputId": "15fb3904-50db-40d7-a0cc-3a940f9bae27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3084"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for sent in train_features:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        truncation=True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train_features[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9xEVEmzpcSS",
        "outputId": "0886d2f7-d1c3-4c7c-9211-afeb6c7fa24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  [Claim]:In her budget speech, Nirmala Sitharaman claimed that the Government distributed 35,000 crore LED bulbs in the country.[Evidences]:Did Finance Minister Nirmala Sitharaman claim the government distributed 35,000 crore LED bulbs under the Ujala scheme? This would imply the Modi govt gave about 300 bulbs to every person in India. At least this is what is being claimed by some social media users who are sharing a screenshot from a news segment on business channel CNBC Awaaz. The photo shows Sitharaman delivering her budget speech while a caption at the bottom reads - \"35,000 crore LED bulb baantein gaye\" (35,000 crore LED bulbs were distributed). The snapshot gives the impression that Sitharaman said this sentence in her speech. Netizens are displaying shock at this whopping number believing that the finance minister's statement is true. Some Congress leaders are also trolling her by sharing the screenshot of the news channel. But, India Today Anti Fake News War Room (AFWA) found that Sitharaman never said that 35,000 crore LED bulbs were distributed in the country in her speech. In fact, she said that approximately 35 crore LED bulbs were distributed under the Ujala scheme. Among many who have shared the news channel's screenshot is Congress spokesperson Shobha Oza who tweeted the picture. Her tweet was retweeted more than 350 times and had over 1,500 likes by the time of writing this story. Former Cabinet Minister in Haryana government, Mahender Pratap Singh also trolled Sitharaman, believing the news to be true. There are some more verified social media users who have shared the same image of the news channel. 125 35000 LED - 280 .. , ...? pic.twitter.com/p8JKRWrMPb Sachin Chaudhary (@SChaudharyINC) July 6, 2019 Every Indian after receiving 300 LED bulbs each, as claimed by Dumb Sitharaman !! (She claims 35000 crore LED bulbs have been distributed, which means every Indian must have got approx 300 each) pic.twitter.com/7Nsz0ZYLm6 Gaurav Pandhi (@GauravPandhi) July 6, 2019 At 1:06:47, in the YouTube video of the Budget 2019 speech, one can hear Finance Minister Nirmala Sitharaman saying \"approximately 35 crore LEDs have been distributed under Ujala Yojana\". The text speech of the budget also reads \"approximately 35 crore LED bulbs\", and not \"35,000 crore LEDs\". Website of UJALA also states that till July 6, more than 35 crore LEDs have been distributed in the country. A senior editor at CNBC Awaaz spoke to us and confirmed that the wrong figure was aired due to a typo which was corrected when noticed. INDIA TODAY FACT CHECK Claim In her budget speech, Nirmala Sitharaman claimed that the Government distributed 35,000 crore LED bulbs in the country. Conclusion Sitharaman never said this in the budget speech. She stated that about 35 crore LED bulbs were distributed under UJALA scheme. JHOOTH BOLE KAUVA KAATE The number of crows determines the intensity of the lie. 1 Crow: Half True 2 Crows: Mostly lies 3 Crows: Absolutely false\n",
            "Token IDs: tensor([    0, 10975, 45699, 42645,  1121,    69,  1229,  1901,     6,   234,\n",
            "         9856,  2331, 33922,   271,  7243,  1695,    14,     5,  1621,  7664,\n",
            "         1718,     6,   151,  4963, 10918, 27353,    11,     5,   247, 31274,\n",
            "        25377, 31688, 42645, 20328,  4090,   692,   234,  9856,  2331, 33922,\n",
            "          271,  7243,  2026,     5,   168,  7664,  1718,     6,   151,  4963,\n",
            "        10918, 27353,   223,     5,   121,   267,  2331,  3552,   116,   152,\n",
            "           74, 25696,     5,  4698,   213, 26390,   851,    59,  2993, 27353,\n",
            "            7,   358,   621,    11,   666,     4,   497,   513,    42,    16,\n",
            "           99,    16,   145,  1695,    30,   103,   592,   433,  1434,    54,\n",
            "           32,  3565,    10, 27314,    31,    10,   340,  2835,    15,   265,\n",
            "         4238, 17826, 11614,   102,  1222,     4,    20,  1345,   924, 33922,\n",
            "          271,  7243,  5830,    69,  1229,  1901,   150,    10,  3747,    23,\n",
            "            5,  2576,  7005,   111,    22,  2022,     6,   151,  4963, 10918,\n",
            "        32384, 17279,  5285,   179,  5100,   242,   113,    36,  2022,     6,\n",
            "          151,  4963, 10918, 27353,    58,  7664,   322,    20, 24512,  2029,\n",
            "            5,  8450,    14, 33922,   271,  7243,    26,    42,  3645,    11,\n",
            "           69,  1901,     4,  5008, 38839,    32, 18534,  4817,    23,    42,\n",
            "        15846,   346, 13294,    14,     5,  2879,  1269,    18,   445,    16,\n",
            "         1528,     4,   993,  1148,   917,    32,    67, 33220,    69,    30,\n",
            "         3565,     5, 27314,     9,     5,   340,  4238,     4,   125,     6,\n",
            "          666,  2477,  9511, 24530,   491,  1771,  8499,    36,  8573,  8460,\n",
            "           43,   303,    14, 33922,   271,  7243,   393,    26,    14,  1718,\n",
            "            6,   151,  4963, 10918, 27353,    58,  7664,    11,     5,   247,\n",
            "           11,    69,  1901,     4,    96,   754,     6,    79,    26,    14,\n",
            "         2219,  1718,  4963, 10918, 27353,    58,  7664,   223,     5,   121,\n",
            "          267,  2331,  3552,     4,  3687,     2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_final = torch.tensor(train_labels_final)\n",
        "val_labels_final = torch.tensor(val_labels_final)"
      ],
      "metadata": {
        "id": "evSioYADp_y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Nk-HGh0yWwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels_final.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC7Tt92syW5Z",
        "outputId": "85518608-eb48-435b-a6ec-e4c7944ad10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3084])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLCxP_iqzspd",
        "outputId": "1cfc2c8b-ead4-4cee-e1b0-3d9583768f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3084"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(list(set(train_labels)))\n",
        "list(set(train_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIo3GxyUrMml",
        "outputId": "ab0e347b-d8df-4202-b2d7-7bb99f399834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['True', 'Half True/False', 'False']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg90AQJcrZFD",
        "outputId": "f90831ed-3370-4693-f87f-405f6fdb628d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# train_poincare_tensor = torch.tensor(poincare_embeddings_final,dtype=torch.float)\n",
        "# difficulty_tensor = torch.tensor(difficulty_level_vectors,dtype=torch.float)\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, train_labels_final)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks,val_labels_final)\n",
        "#"
      ],
      "metadata": {
        "id": "KOK3P-9Gra78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            sampler = RandomSampler(dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "metadata": {
        "id": "c6ALqnRkrjBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class MultiClassClassifier(nn.Module):\n",
        "    def __init__(self, bert_model_path, labels_count, hidden_dim=768, mlp_dim=500, extras_dim=100, dropout=0.1, freeze_bert=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.roberta = AutoModel.from_pretrained(bert_model_path,output_hidden_states=True,output_attentions=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, mlp_dim),\n",
        "            nn.ReLU(),\n",
        "            # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # # nn.ReLU(),\n",
        "            # # nn.Linear(mlp_dim, mlp_dim),\n",
        "            # nn.ReLU(),\n",
        "            nn.Linear(mlp_dim, labels_count)\n",
        "        )\n",
        "        # self.softmax = nn.LogSoftmax(dim=1)\n",
        "        if freeze_bert:\n",
        "            print(\"Freezing layers\")\n",
        "            for param in self.roberta.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, tokens, masks):\n",
        "        output = self.roberta(tokens, attention_mask=masks)\n",
        "        dropout_output = self.dropout(output[\"pooler_output\"])\n",
        "        # concat_output = torch.cat((dropout_output, topic_emb), dim=1)\n",
        "        # concat_output = self.dropout(concat_output)\n",
        "        mlp_output = self.mlp(dropout_output)\n",
        "        # proba = self.sigmoid(mlp_output)\n",
        "        # proba = self.softmax(mlp_output)\n",
        "\n",
        "        return mlp_output"
      ],
      "metadata": {
        "id": "cKSZPwobrl8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Loads BertForSequenceClassification, the pretrained BERT model with a single\n",
        "model = MultiClassClassifier('roberta-large-mnli',num_classes, 1024,768,140,dropout=0.1,freeze_bert=False)\n",
        "\n",
        "# model.load_state_dict(torch.load(\"model_bert_difficulty_prediction/model_weights\"))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAxysrcNsFl8",
        "outputId": "263ae100-1064-40f2-dcbd-fb702692d9af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiClassClassifier(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-23): 24 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=1024, out_features=768, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iilNEZRCsJjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awQ2Y9Jb3kht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23f25c7-230b-42d8-9c80-0f7432e9fec9"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ys-M4-e3khv"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrYqErOD3khx",
        "outputId": "22b99e9d-ca60-48d5-ddc6-483124ba098e"
      },
      "source": [
        "len(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "621"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWVSE9LM3kh0",
        "outputId": "b2281f5f-716a-4fd8-c03d-29db9c46c368"
      },
      "source": [
        "1935 * 32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61920"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcvxVVi63kh3"
      },
      "source": [
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUw3zm6g3kh5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta6zfUTa3kh7"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFq9gd5kQSHb"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_nmuoSgQ5t3"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.roberta.encoder.layer[0:5].parameters():\n",
        "    param.requires_grad=False"
      ],
      "metadata": {
        "id": "ugVDrHu20c8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1rDO58zMfc8"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LhAy2hZ3kh9",
        "outputId": "d670686d-962f-4a24-efdb-03fb7cc21c66"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss,\n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "early_stopping = EarlyStopping(patience=2, verbose=True)\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_accuracy = 0\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questimport gensim.downloader as api\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        # b_poincare = batch[2].to(device)\n",
        "        # b_difficulty = batch[3].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        # skill_labels = batch[3].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        probas = model(b_input_ids,b_input_mask)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        loss = loss_func(probas, b_labels)\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        # scheduler.step()\n",
        "        logits = probas.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        total_train_accuracy += flat_accuracy(logits, label_ids)\n",
        "    avg_train_accuracy = total_train_accuracy / len(train_dataloader)\n",
        "    print(\" Train Accuracy: {0:.2f}\".format(avg_train_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        # b_poincare = batch[2].to(device)\n",
        "        # b_difficulty = batch[3].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        # skill_labels = batch[3].to(device)\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "\n",
        "          logits = model(b_input_ids,b_input_mask)\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        loss = loss_func(logits, b_labels)\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    early_stopping(avg_val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break\n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    output_dir = 'model_roberta_large_oracle/'\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    print(\"Saving model to %s\" % output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    torch.save(model.state_dict(), os.path.join(output_dir, 'model_weights'))\n",
        "\n",
        "    !rm -rf \"/content/drive/My Drive/ecir_compnumfacts/model_roberta_large_oracle\"\n",
        "    !mv model_roberta_large_oracle \"/content/drive/My Drive/ecir_compnumfacts/\"\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n",
            "  Batch    40  of    621.    Elapsed: 0:01:23.\n",
            "  Batch    80  of    621.    Elapsed: 0:02:51.\n",
            "  Batch   120  of    621.    Elapsed: 0:04:23.\n",
            "  Batch   160  of    621.    Elapsed: 0:05:54.\n",
            "  Batch   200  of    621.    Elapsed: 0:07:25.\n",
            "  Batch   240  of    621.    Elapsed: 0:08:56.\n",
            "  Batch   280  of    621.    Elapsed: 0:10:28.\n",
            "  Batch   320  of    621.    Elapsed: 0:11:59.\n",
            "  Batch   360  of    621.    Elapsed: 0:13:31.\n",
            "  Batch   400  of    621.    Elapsed: 0:15:02.\n",
            "  Batch   440  of    621.    Elapsed: 0:16:33.\n",
            "  Batch   480  of    621.    Elapsed: 0:18:05.\n",
            "  Batch   520  of    621.    Elapsed: 0:19:36.\n",
            "  Batch   560  of    621.    Elapsed: 0:21:07.\n",
            "  Batch   600  of    621.    Elapsed: 0:22:39.\n",
            " Train Accuracy: 0.66\n",
            "\n",
            "  Average training loss: 0.73\n",
            "  Training epcoh took: 0:23:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.70\n",
            "Validation loss decreased (inf --> 0.643350).  Saving model ...\n",
            "  Validation Loss: 0.64\n",
            "  Validation took: 0:02:35\n",
            "Saving model to model_roberta_large_oracle/\n",
            "\n",
            "======== Epoch 2 / 20 ========\n",
            "Training...\n",
            "  Batch    40  of    621.    Elapsed: 0:01:32.\n",
            "  Batch    80  of    621.    Elapsed: 0:03:04.\n",
            "  Batch   120  of    621.    Elapsed: 0:04:35.\n",
            "  Batch   160  of    621.    Elapsed: 0:06:07.\n",
            "  Batch   200  of    621.    Elapsed: 0:07:38.\n",
            "  Batch   240  of    621.    Elapsed: 0:09:09.\n",
            "  Batch   280  of    621.    Elapsed: 0:10:41.\n",
            "  Batch   320  of    621.    Elapsed: 0:12:12.\n",
            "  Batch   360  of    621.    Elapsed: 0:13:43.\n",
            "  Batch   400  of    621.    Elapsed: 0:15:15.\n",
            "  Batch   440  of    621.    Elapsed: 0:16:46.\n",
            "  Batch   480  of    621.    Elapsed: 0:18:17.\n",
            "  Batch   520  of    621.    Elapsed: 0:19:49.\n",
            "  Batch   560  of    621.    Elapsed: 0:21:20.\n",
            "  Batch   600  of    621.    Elapsed: 0:22:51.\n",
            " Train Accuracy: 0.73\n",
            "\n",
            "  Average training loss: 0.60\n",
            "  Training epcoh took: 0:23:39\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.72\n",
            "EarlyStopping counter: 1 out of 2\n",
            "  Validation Loss: 0.64\n",
            "  Validation took: 0:02:32\n",
            "Saving model to model_roberta_large_oracle/\n",
            "\n",
            "======== Epoch 3 / 20 ========\n",
            "Training...\n",
            "  Batch    40  of    621.    Elapsed: 0:01:32.\n",
            "  Batch    80  of    621.    Elapsed: 0:03:03.\n",
            "  Batch   120  of    621.    Elapsed: 0:04:35.\n",
            "  Batch   160  of    621.    Elapsed: 0:06:06.\n",
            "  Batch   200  of    621.    Elapsed: 0:07:37.\n",
            "  Batch   240  of    621.    Elapsed: 0:09:08.\n",
            "  Batch   280  of    621.    Elapsed: 0:10:39.\n",
            "  Batch   320  of    621.    Elapsed: 0:12:11.\n",
            "  Batch   360  of    621.    Elapsed: 0:13:42.\n",
            "  Batch   400  of    621.    Elapsed: 0:15:13.\n",
            "  Batch   440  of    621.    Elapsed: 0:16:45.\n",
            "  Batch   480  of    621.    Elapsed: 0:18:16.\n",
            "  Batch   520  of    621.    Elapsed: 0:19:47.\n",
            "  Batch   560  of    621.    Elapsed: 0:21:18.\n",
            "  Batch   600  of    621.    Elapsed: 0:22:50.\n",
            " Train Accuracy: 0.77\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:23:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:18:41 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y85_jMDiw9uP",
        "outputId": "3d185869-d3c4-4d52-9007-d894d3dc6427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login"
      ],
      "metadata": {
        "id": "TEEKmPey0a8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "33cc7df771c845bd869d6b5124f2604d",
            "794716544ed3491aba47432a4f3afca4",
            "f64930120a7748eaa8a743c77e52cc4d",
            "931cbe93dc6546ba970a79e0cbf678bd",
            "18b0770757c241de8253b1d94ee568fe",
            "0d7e62772c6f451d9575dd5df95d879c",
            "89226fc74b2c44a2978c4d0b43b60739",
            "cf150bd16c424916a8ba79e763d07f1d",
            "469f372a38644513abf1374edc48ee3d",
            "ad973a985d3a421eaa5c1a7ca55420ed",
            "71e781b197b5496e8809b7fff046a20e",
            "8bdd37fccf354d9793047799a966f2a0",
            "39317c1aa3694777947eab03b2dd3ff5",
            "c71f8c507eab42e3baa08939664d3029",
            "804dbceb1d564e0e8a0fdc5e57f2c489",
            "cbb79f0a4ca246a18381b836665264e4",
            "089e03c3f97749b99e6493cd58176603",
            "f6339b7381c54dda8b7876bca36c3054",
            "31e6b85700304187bf5197da351a125e",
            "248d065f02eb4f57a33b60df8dd9fb24",
            "f07654bb49c64b1aa30940181d5e4574",
            "34f0c3999b5c4bf295102050cb6052d4",
            "a76ca4bdf1784163878dae276beca5d5",
            "cef13963e753410c8812b92daebdd48f",
            "169e51f8ece34774baceefbbdff5276d",
            "fb7ce11bf3a14bc3bbca96cbbb4f45ef",
            "521fe75d24e2402f9a4566d82b4602fd",
            "6991b5be37164ec09eb84d9935c4a1f5",
            "f0610958751c4fcba8cd0a042c79dcd0",
            "261eecd1fd6e4b17a9e9bcb574bc9f5b",
            "0de8bc5290ba41a78ab6cac1a9e99c13",
            "0c92603a817143ab8b4bf460a09f3245"
          ]
        },
        "id": "MFR-s_8ZtATC",
        "outputId": "ba9e4dfc-d784-4191-fe58-36b5b97a648d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33cc7df771c845bd869d6b5124f2604d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LE.classes_"
      ],
      "metadata": {
        "id": "GWkkt0F4Ifwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xy__BpY8VOQp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}